# 3. Develop a chatbot that serves as an expert in a specific domain, capable of answering complex queries and explaining concepts. Use the arXiv dataset ( https://www.kaggle.com/datasets/Cornell-University/arxiv) for scientific papers in various fields. Train the chatbot on a specific subset of the arXiv dataset (e.g., computer science). Implement advanced NLP techniques for information extraction, summarization, and user open source LLM for explanation generation. Expected Outcome: A chatbot that can discuss advanced topics in the chosen field, provide summaries of research papers, and explain complex concepts. Ability to handle follow-up questions on complex topics. Implement using Streamlit with features for paper searching and concept visualization

# Seperator
- I extracted only the *cs.ds* research paper files from the Arxiv file that had been given from the link.
- From that I have choosen 1000 data files to train my model
- My model secured over 94% in the training.
# Train_stream
- Train_stream.py is the streamlit model which will give the output screen.
- In the left sidebar there will be a choosing option for the research paper details that will help the researchers
- Based on the question you ask the model will provide the output from the trained model (pkl, keras)

# Working Video
Link: https://www.linkedin.com/posts/gugan-r-92b4b2261_nullclass-project-compeletion-activity-7284117391205191680-6YEp?utm_source=share&utm_medium=member_desktop
